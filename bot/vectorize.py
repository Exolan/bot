import json
import asyncio
import aiomysql
import torch
import torch.nn.functional as F
from torch import Tensor
from transformers import AutoTokenizer, AutoModel
from config import DB_HOST, DB_NAME, DB_PASSWORD, DB_USER

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
tokenizer = AutoTokenizer.from_pretrained("intfloat/multilingual-e5-large-instruct")
model = AutoModel.from_pretrained("intfloat/multilingual-e5-large-instruct")

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
DB_CONFIG = {
    "host": DB_HOST,
    "user": DB_USER,
    "password": DB_PASSWORD,
    "db": DB_NAME,
}

def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:
    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)
    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]

def embed_text(text: str) -> list:
    instruct_text = f'Instruct: Given a web search query, retrieve relevant passages that answer the query\nQuery: {text}'
    inputs = tokenizer(instruct_text, max_length=512, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
    embedding = average_pool(outputs.last_hidden_state, inputs['attention_mask'])
    embedding = F.normalize(embedding, p=2, dim=1)
    return embedding.squeeze(0).tolist()  # —É–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (1, 1024) ‚Üí (1024,)

async def update_vectors(pool, table_name, id_column, name_column, text_column, vector_column, exclude_names=None):
    """ –ö–æ–¥–∏—Ä—É–µ—Ç –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (name + text) –∏–∑ –ë–î –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –µ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ """
    exclude_names = exclude_names or []
    async with pool.acquire() as conn:
        async with conn.cursor() as cursor:
            # –ò–∑–º–µ–Ω—ë–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ –±–µ–∑ –≤–µ–∫—Ç–æ—Ä–∞ –∏–ª–∏ —Å –ø—É—Å—Ç—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º
            query = f"""
                SELECT {id_column}, {name_column}, {text_column} 
                FROM {table_name} 
                WHERE {text_column} IS NOT NULL
                AND ({vector_column} IS NULL OR JSON_LENGTH({vector_column}) = 0)
            """
            if exclude_names:
                placeholders = ', '.join(['%s'] * len(exclude_names))
                query += f" AND {name_column} NOT IN ({placeholders})"

            await cursor.execute(query, exclude_names)
            rows = await cursor.fetchall()

            if not rows:
                print(f"‚è© –ù–µ—Ç –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ {table_name}")
                return

            print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(rows)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ {table_name}")

            for row_id, name, text in rows:
                full_text = f"{name}. {text}" if name else text
                try:
                    vector = embed_text(full_text)
                    vector_json = json.dumps(vector)

                    await cursor.execute(
                        f"UPDATE {table_name} SET {vector_column} = %s WHERE {id_column} = %s",
                        (vector_json, row_id)
                    )
                    print(f"‚úÖ –û–±–Ω–æ–≤–ª—ë–Ω {table_name}: ID {row_id}")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {table_name} ID {row_id}: {str(e)}")

            await conn.commit()

async def main():
    print("‚ö° –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤...")

    pool = await aiomysql.create_pool(**DB_CONFIG)

    await update_vectors(pool, "themes", "theme_id", "theme_name", "theme_text", "theme_vector")
    await update_vectors(pool, "subthemes", "subtheme_id", "subtheme_name", "subtheme_text", "subtheme_vector")

    pool.close()
    await pool.wait_closed()

    print("üéâ –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    asyncio.run(main())
